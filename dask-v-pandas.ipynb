{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask Acceleration vs Pandas\n",
    "\n",
    "This notebook explores speed advantages realized by using the Dask library over Pandas for dataframe operations in Python.\n",
    "\n",
    "| Tech | Version |\n",
    "| --- | --- |\n",
    "| Python | 3.6.9 |\n",
    "| jupyter-notebook | 6.0.1 |\n",
    "| pandas | 1.0.3 |\n",
    "| dask | 2.17.2\n",
    "\n",
    "Hat - tip to Saturn Cloud's [Your Practical Guide to Dask](https://www.saturncloud.io/s/practical-guide-to-dask/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import random\n",
    "import pandas as pd\n",
    "import os # for directory operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Randomize stock data in Python and save the data as a Pandas dataframe.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating 1M random stock records\n",
    "num_rows = 1000000\n",
    "\n",
    "symbols = [\"AAPL\", \"AMD\", \"GOOG\", \"MSFT\", \"NVDA\"]\n",
    "prices = [random.randint(1, 500) for _ in range(50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_data(symbols, prices):\n",
    "    '''\n",
    "    function to generate random stock data from the\n",
    "    `symbols` list and the randomized `prices` list\n",
    "    '''\n",
    "    return {\"symbol\": random.sample(symbols, 1)[0],\n",
    "            \"price\": random.sample(prices, 1)[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the function to generate stock data for the\n",
    "# number of rows instantiated in `num_rows`\n",
    "stock_data = [get_stock_data(symbols, prices) for _ in range(num_rows)]\n",
    "\n",
    "# instantiate data as a pandas dataframe\n",
    "stock_df = pd.DataFrame(stock_data,\n",
    "                        columns=[\"symbol\", \"price\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Export stock data to a csv file.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMD</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol  price\n",
       "0   AAPL    229\n",
       "1   GOOG     47\n",
       "2   AAPL    213\n",
       "3    AMD    325\n",
       "4   NVDA    276"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save `stock_df` as a csv file in the data subdirectory\n",
    "if not os.path.exists('data'):\n",
    "    os.makedir('data')\n",
    "\n",
    "# prefix filename with '__rc__' to .gitignore\n",
    "stock_df.to_csv(\"data/_rc_stock_data.csv\")\n",
    "\n",
    "# preview the dataframe\n",
    "stock_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load csv Data to a Dask Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "# loading csv data to a dask dataframe\n",
    "dask_df = dd.read_csv(\"data/_rc_stock_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Repartition dask data to sizes of 100MB-or-less, per [official documentation](https://docs.dask.org/en/latest/dataframe-best-practices.html#repartition-to-reduce-overhead)__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repartitioning dask dataframe from csv\n",
    "dask_df = dask_df.repartition(partition_size=\"100MB\")\n",
    "\n",
    "# loading pandas dataframe from csv\n",
    "pandas_df = pd.read_csv(\"data/_rc_stock_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute CPU Acceleration with Dask vs Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Calculate Means__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas execution time:  0.00275\n",
      "------------------------------\n",
      "\n",
      "dask execution time:  0.00224\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "# computing and comparing task execution\n",
    "start = timer()\n",
    "\n",
    "# Calculate mean using pandas\n",
    "pandas_df[\"price\"].mean()\n",
    "\n",
    "end = timer()\n",
    "\n",
    "# print time elapsed in seconds\n",
    "print(\"pandas execution time: \", round(end - start, 5))\n",
    "print(\"-\"*30)\n",
    "\n",
    "start = timer()\n",
    "\n",
    "# Calculate mean using Dask\n",
    "dask_df[\"price\"].mean()\n",
    "\n",
    "end = timer()\n",
    "\n",
    "# print time elapsed in seconds\n",
    "print(\"\\ndask execution time: \", round(end - start, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Filter dataframes__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas execution time:  0.02367\n",
      "------------------------------\n",
      "\n",
      "dask execution time:  0.00097\n"
     ]
    }
   ],
   "source": [
    "start_p = timer()\n",
    "# Filtering by price in Pandas\n",
    "pandas_df[pandas_df[\"price\"] > 250]\n",
    "end_p = timer()\n",
    "pandas_time = round(end_p - start_p, 5)\n",
    "print(\"pandas execution time: \", pandas_time)\n",
    "print(\"-\"*30)\n",
    "\n",
    "start_d = timer()\n",
    "# Filtering by price in Dask\n",
    "dask_df[dask_df[\"price\"] > 250]\n",
    "end_d = timer()\n",
    "dask_time = round(end_d - start_d, 5)\n",
    "print(\"\\ndask execution time: \", dask_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.402 % speed increase\n"
     ]
    }
   ],
   "source": [
    "# calculating acceleration for dask execution over pandas\n",
    "print(round(pandas_time/dask_time, 3), \n",
    "      \"% speed increase\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Add dataframes__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas execution time:  0.41559\n",
      "------------------------------\n",
      "\n",
      "dask execution time:  0.01944\n",
      "------------------------------ \n",
      "\n",
      "21.378 % increase in speed\n"
     ]
    }
   ],
   "source": [
    "start_p = timer()\n",
    "# Adding big DataFrames in Pandas\n",
    "pandas_df + pandas_df + pandas_df + pandas_df + pandas_df\n",
    "end_p = timer()\n",
    "pandas_time = round(end_p - start_p, 5)\n",
    "print(\"pandas execution time: \", pandas_time)\n",
    "print(\"-\"*30)\n",
    "\n",
    "start_d = timer()\n",
    "# Adding big DataFrames in Dask\n",
    "dask_df + dask_df + dask_df + dask_df + dask_df\n",
    "end_d = timer()\n",
    "dask_time = round(end_d - start_d, 5)\n",
    "print(\"\\ndask execution time: \", dask_time)\n",
    "\n",
    "# calculating dask speed improvement\n",
    "print(\"-\"*30, \"\\n\")\n",
    "\n",
    "print(round(pandas_time/dask_time, 3), \n",
    "      \"% increase in speed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute GPU Acceleration with Dask vs Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The cuDF library enables GPU acceleration for Pandas - Dask dataframe computation.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cudf\n",
    "\n",
    "# # reinstantiate `dask_df` for use with GPU backend\n",
    "# dask_df = dask_df.map_partitions(cudf.from_pandas) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ======_cuDF no longer available via pip [or for Windows???]_ ======\n",
    "\n",
    "__Resume in containerized environment.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch-env] *",
   "language": "python",
   "name": "conda-env-pytorch-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "203.537px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
