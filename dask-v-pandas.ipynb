{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask Acceleration vs Pandas\n",
    "\n",
    "This notebook explores speed advantages realized by using the Dask library over Pandas for dataframe operations in Python.\n",
    "\n",
    "Local system:\n",
    "\n",
    "| Tech | Version |\n",
    "| --- | --- |\n",
    "| Python | 3.6.9 |\n",
    "| jupyter-notebook | 6.0.1 |\n",
    "| pandas | 1.0.3 |\n",
    "| dask | 2.17.2 |\n",
    "| x64 - based PC | i7 - 2.60 GHz |\n",
    "| RAM | 16.0 GB |\n",
    "\n",
    "Hat - tip to Saturn Cloud's [Your Practical Guide to Dask](https://www.saturncloud.io/s/practical-guide-to-dask/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing library to measure execution time\n",
    "import timeit\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# starting timer for complete notebook execution\n",
    "notebook_start = timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import random\n",
    "import pandas as pd\n",
    "import os # for directory operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Randomize stock data in Python and save the data as a Pandas dataframe.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating 1M random stock records\n",
    "num_rows = 1000000\n",
    "\n",
    "symbols = [\"AAPL\", \"AMD\", \"GOOG\", \"MSFT\", \"NVDA\"]\n",
    "prices = [random.randint(1, 500) for _ in range(50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_data(symbols, prices):\n",
    "    '''\n",
    "    function to generate random stock data from the\n",
    "    `symbols` list and the randomized `prices` list\n",
    "    '''\n",
    "    return {\"symbol\": random.sample(symbols, 1)[0],\n",
    "            \"price\": random.sample(prices, 1)[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the function to generate stock data for the\n",
    "# number of rows instantiated in `num_rows`\n",
    "stock_data = [get_stock_data(symbols, prices) for _ in range(num_rows)]\n",
    "\n",
    "# instantiate data as a pandas dataframe\n",
    "stock_df = pd.DataFrame(stock_data,\n",
    "                        columns=[\"symbol\", \"price\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Export stock data to a csv file.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol  price\n",
       "0   GOOG     83\n",
       "1   AAPL    169\n",
       "2   GOOG    191\n",
       "3   MSFT    477\n",
       "4   MSFT    477"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save `stock_df` as a csv file in the data subdirectory\n",
    "if not os.path.exists('data'):\n",
    "    os.makedir('data')\n",
    "\n",
    "# prefix filename with '__rc__' to .gitignore\n",
    "stock_df.to_csv(\"data/_rc_stock_data.csv\")\n",
    "\n",
    "# preview the dataframe\n",
    "stock_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load csv Data to a Dask Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "# loading csv data to a dask dataframe\n",
    "dask_df = dd.read_csv(\"data/_rc_stock_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Repartition dask data to sizes of 100MB-or-less, per [official documentation](https://docs.dask.org/en/latest/dataframe-best-practices.html#repartition-to-reduce-overhead)__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repartitioning dask dataframe from csv\n",
    "dask_df = dask_df.repartition(partition_size=\"100MB\")\n",
    "\n",
    "# loading pandas dataframe from csv\n",
    "pandas_df = pd.read_csv(\"data/_rc_stock_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute CPU Acceleration with Dask vs Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create functions to calculate mean for the same dataframe in each of the two libraries.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_mean():\n",
    "    '''Calculates mean using pandas\n",
    "    ''' \n",
    "    pandas_df[\"price\"].mean()\n",
    "    \n",
    "def dask_mean():\n",
    "    '''Calculate means using dask\n",
    "    ''' \n",
    "    dask_df[\"price\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Compare Calculating Means (single iteration)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pandas execution time:  0.00116\n",
      "------------------------------\n",
      "\n",
      "dask execution time:  0.00134\n"
     ]
    }
   ],
   "source": [
    "print(\"\\npandas execution time: \", round(\n",
    "    timeit.timeit(pandas_mean, number=1), 5)\n",
    "     )\n",
    "print(\"-\"*30)\n",
    "\n",
    "print(\"\\ndask execution time: \", round(\n",
    "    timeit.timeit(dask_mean, number=1), 5)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas execution time:  0.0013\n",
      "------------------------------\n",
      "\n",
      "dask execution time:  0.0015\n"
     ]
    }
   ],
   "source": [
    "# computing and comparing task execution with `timer()`\n",
    "start = timer()\n",
    "\n",
    "# Calculate mean using pandas\n",
    "pandas_df[\"price\"].mean()\n",
    "\n",
    "end = timer()\n",
    "\n",
    "# print time elapsed in seconds\n",
    "print(\"pandas execution time: \", round(end - start, 5))\n",
    "print(\"-\"*30)\n",
    "\n",
    "start = timer()\n",
    "\n",
    "# Calculate mean using Dask\n",
    "dask_df[\"price\"].mean()\n",
    "\n",
    "end = timer()\n",
    "\n",
    "# print time elapsed in seconds\n",
    "print(\"\\ndask execution time: \", round(end - start, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Compare Calculating Means (10K iterations)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pandas execution time:  8.8\n",
      "------------------------------\n",
      "\n",
      "dask execution time:  10.14\n"
     ]
    }
   ],
   "source": [
    "print(\"\\npandas execution time: \", round(\n",
    "    timeit.timeit(pandas_mean, number=10000), 2)\n",
    "     )\n",
    "print(\"-\"*30)\n",
    "\n",
    "print(\"\\ndask execution time: \", round(\n",
    "    timeit.timeit(dask_mean, number=10000), 2)\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Compare Calculating Means (100K iterations)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing means\n",
    "p_mean = round(timeit.timeit(pandas_mean, number=100000), 2)\n",
    "d_mean = round(timeit.timeit(dask_mean, number=100000), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pandas execution time:  86.12\n",
      "------------------------------\n",
      "\n",
      "dask execution time:  102.0\n",
      "\n",
      "Calculating means is about -18.44 % faster over a large dataset, with dask on CPU.\n"
     ]
    }
   ],
   "source": [
    "# comparing means\n",
    "print(\"\\npandas execution time: \", p_mean)\n",
    "print(\"-\"*30)\n",
    "print(\"\\ndask execution time: \", d_mean)\n",
    "\n",
    "print(\"\\nCalculating means is about\",\n",
    "      round((p_mean - d_mean) / p_mean*100, 2),\n",
    "      \"% faster over a large dataset, with dask on CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create functions to filter dataframe in each of the two libraries.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_filter():\n",
    "    '''Filters by price using pandas\n",
    "    ''' \n",
    "    pandas_df[pandas_df[\"price\"] > 250]\n",
    "    \n",
    "def dask_filter():\n",
    "    '''Filters by price using dask\n",
    "    ''' \n",
    "    dask_df[dask_df[\"price\"] > 250]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Compare Filtering Dataframes (single iteration)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pandas execution time:  0.02528\n",
      "------------------------------\n",
      "\n",
      "dask execution time:  0.00095\n"
     ]
    }
   ],
   "source": [
    "print(\"\\npandas execution time: \", round(\n",
    "    timeit.timeit(pandas_filter, number=1), 5)\n",
    "     )\n",
    "print(\"-\"*30)\n",
    "\n",
    "print(\"\\ndask execution time: \", round(\n",
    "    timeit.timeit(dask_filter, number=1), 5)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas execution time:  0.02231\n",
      "------------------------------\n",
      "\n",
      "dask execution time:  0.00101\n"
     ]
    }
   ],
   "source": [
    "# computing and comparing task execution with `timer()`\n",
    "start_p = timer()\n",
    "# Filtering by price in Pandas\n",
    "pandas_df[pandas_df[\"price\"] > 250]\n",
    "end_p = timer()\n",
    "pandas_time = round(end_p - start_p, 5)\n",
    "\n",
    "print(\"pandas execution time: \", pandas_time)\n",
    "print(\"-\"*30)\n",
    "\n",
    "start_d = timer()\n",
    "# Filtering by price in Dask\n",
    "dask_df[dask_df[\"price\"] > 250]\n",
    "end_d = timer()\n",
    "dask_time = round(end_d - start_d, 5)\n",
    "\n",
    "print(\"\\ndask execution time: \", dask_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Compare Filtering Dataframes (10K iterations)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pandas execution time:  186.23\n",
      "------------------------------\n",
      "\n",
      "dask execution time:  6.79\n"
     ]
    }
   ],
   "source": [
    "print(\"\\npandas execution time: \", round(\n",
    "    timeit.timeit(pandas_filter, number=10000), 2)\n",
    "     )\n",
    "print(\"-\"*30)\n",
    "\n",
    "print(\"\\ndask execution time: \", round(\n",
    "    timeit.timeit(dask_filter, number=10000), 2)\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Compare Filtering Dataframes (100K iterations)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pandas execution time:  1873.04\n",
      "------------------------------\n",
      "\n",
      "dask execution time:  68.34\n"
     ]
    }
   ],
   "source": [
    "# computing filter time\n",
    "p_filter = round(timeit.timeit(pandas_filter, number=100000), 2)\n",
    "\n",
    "print(\"\\npandas execution time: \", p_filter)\n",
    "print(\"-\"*30)\n",
    "\n",
    "d_filter = round(timeit.timeit(dask_filter, number=100000), 2)\n",
    "\n",
    "print(\"\\ndask execution time: \", d_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtering is about 96.35 % faster over a large dataset, with dask on CPU.\n"
     ]
    }
   ],
   "source": [
    "# comparing filter execution time\n",
    "print(\"\\nFiltering is about\",\n",
    "      round((p_filter - d_filter) / p_filter*100, 2),\n",
    "      \"% faster over a large dataset, with dask on CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create functions to add dataframes in each of the two libraries.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_add():\n",
    "    '''Adds dataframes together using pandas\n",
    "    ''' \n",
    "    pandas_df + pandas_df + pandas_df + pandas_df + pandas_df\n",
    "    \n",
    "def dask_add():\n",
    "    '''Adds dataframes together using dask\n",
    "    ''' \n",
    "    dask_df + dask_df + dask_df + dask_df + dask_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Compare Adding Dataframes (single iteration)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pandas execution time:  0.43025\n",
      "------------------------------\n",
      "\n",
      "dask execution time:  0.02012\n"
     ]
    }
   ],
   "source": [
    "print(\"\\npandas execution time: \", round(\n",
    "    timeit.timeit(pandas_add, number=1), 5)\n",
    "     )\n",
    "print(\"-\"*30)\n",
    "\n",
    "print(\"\\ndask execution time: \", round(\n",
    "    timeit.timeit(dask_add, number=1), 5)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas execution time:  0.39475\n",
      "------------------------------\n",
      "\n",
      "dask execution time:  0.01891\n",
      "------------------------------ \n",
      "\n",
      "95.21 % increase in speed\n"
     ]
    }
   ],
   "source": [
    "start_p = timer()\n",
    "# adding big dataframes in pandas\n",
    "pandas_df + pandas_df + pandas_df + pandas_df + pandas_df\n",
    "end_p = timer()\n",
    "pandas_time = round(end_p - start_p, 5)\n",
    "print(\"pandas execution time: \", pandas_time)\n",
    "print(\"-\"*30)\n",
    "\n",
    "start_d = timer()\n",
    "# adding big dataframes in dask\n",
    "dask_df + dask_df + dask_df + dask_df + dask_df\n",
    "end_d = timer()\n",
    "dask_time = round(end_d - start_d, 5)\n",
    "print(\"\\ndask execution time: \", dask_time)\n",
    "\n",
    "# calculating dask speed improvement\n",
    "print(\"-\"*30, \"\\n\")\n",
    "\n",
    "print(round((pandas_time - dask_time) / pandas_time*100, 3), \n",
    "      \"% increase in speed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Compare Adding Dataframes (10K iterations)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pandas execution time:  4017.73\n",
      "------------------------------\n",
      "\n",
      "dask execution time:  190.97\n",
      "\n",
      "Adding dataframes is about 95.25 % faster over a large dataset, with dask on CPU.\n"
     ]
    }
   ],
   "source": [
    "# compute\n",
    "p_add = timeit.timeit(pandas_add, number=10000)\n",
    "\n",
    "print(\"\\npandas execution time: \", round(\n",
    "    p_add, 2)\n",
    "     )\n",
    "print(\"-\"*30)\n",
    "\n",
    "d_add = timeit.timeit(dask_add, number=10000)\n",
    "\n",
    "print(\"\\ndask execution time: \", round(\n",
    "    d_add, 2)\n",
    "     )\n",
    "\n",
    "print(\"\\nAdding dataframes is about\",\n",
    "      round((p_add - d_add) / p_add*100, 2),\n",
    "      \"% faster over a large dataset, with dask on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6632.79\n"
     ]
    }
   ],
   "source": [
    "# ending timer for complete notebook execution\n",
    "notebook_end = timer()\n",
    "\n",
    "# calculating time for complete notebook execution\n",
    "notebook_duration = notebook_end - notebook_start\n",
    "print(round(notebook_duration, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Compare Adding Dataframes (100K iterations)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1948.6294115"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute\n",
    "# --time prohibitive--\n",
    "# p_add = timeit.timeit(pandas_add, number=100000)\n",
    "\n",
    "# compute for dask, only, in seconds\n",
    "d_add = timeit.timeit(dask_add, number=100000)\n",
    "d_add"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 50,
   "metadata": {},
=======
   "execution_count": null,
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
>>>>>>> 7db093ac767859432e52c298df1d91c42fd012c7
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dask execution time:  1949 2\n",
      "\n",
      "Adding dataframes takes about 32.48 minutes over the large datasets, with dask on CPU.\n"
     ]
    }
   ],
   "source": [
    "# print(\"\\npandas execution time: \", round(\n",
    "#     p_add, 2)\n",
    "#      )\n",
    "# print(\"-\"*30)\n",
    "\n",
    "print(\"\\ndask execution time: \", round(\n",
    "    d_add), 2)\n",
    "\n",
    "print(\"\\nAdding dataframes takes about\",\n",
<<<<<<< HEAD
=======
    "      round(((p_add - d_add) / p_add*100, 2)/60),\n",
    "      \"minutes over large datasets, with dask on CPU.\")"
>>>>>>> 7db093ac767859432e52c298df1d91c42fd012c7
    "      round(d_add/60, 2),\n",
    "      \"minutes over the large datasets, with dask on CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute GPU Acceleration with Dask vs Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The cuDF library enables GPU acceleration for Pandas - Dask dataframe computation.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cudf\n",
    "\n",
    "# # reinstantiate `dask_df` for use with GPU backend\n",
    "# dask_df = dask_df.map_partitions(cudf.from_pandas) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ======_cuDF no longer available via pip [or for Windows???]_ ======\n",
    "\n",
    "__Resume in containerized environment.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ending timer for complete notebook execution\n",
    "notebook_end = timer()\n",
    "\n",
    "# calculating time for complete notebook execution\n",
    "notebook_duration = notebook_end - notebook_start\n",
    "print(round(notebook_duration, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch-env] *",
   "language": "python",
   "name": "conda-env-pytorch-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "203.537px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
